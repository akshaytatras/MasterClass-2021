{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP_Applications_Text_Classification_Deep_Learning_Sequential_Models_LSTMs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysuLv6mAGYRG"
      },
      "source": [
        "# Text Classification - Deep Learning Sequential Models - LSTMs\n",
        "\n",
        "\n",
        "Another new and interesting approach to supervised deep learning is the use\n",
        "of recurrent neural networks (RNNs) and long short-term memory networks (LSTMs)\n",
        "which also considers the sequence of data (words, events and so on). These are more\n",
        "advanced models than your regular fully connected deep networks and usually take\n",
        "more time to train.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV2VaftX3JO4",
        "outputId": "f31cd272-bfb6-4d05-a912-53990219bbec"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Apr  6 12:11:38 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw7MTNQvzCeG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05bfcb91-afa5-460c-a979-efa5d954800b"
      },
      "source": [
        "!pip install contractions\n",
        "!pip install textsearch\n",
        "!pip install tqdm\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading https://files.pythonhosted.org/packages/0a/04/d5e0bb9f2cef5d15616ebf68087a725c5dbdd71bd422bcfb35d709f98ce7/contractions-0.0.48-py2.py3-none-any.whl\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading https://files.pythonhosted.org/packages/d3/fe/021d7d76961b5ceb9f8d022c4138461d83beff36c3938dc424586085e559/textsearch-0.0.21-py2.py3-none-any.whl\n",
            "Collecting anyascii\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/c7/61370d9e3c349478e89a5554c1e5d9658e1e3116cc4f2528f568909ebdf1/anyascii-0.1.7-py3-none-any.whl (260kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 7.6MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/c2/eae730037ae1cbbfaa229d27030d1d5e34a1e41114b21447d1202ae9c220/pyahocorasick-1.4.2.tar.gz (321kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 13.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85390 sha256=5fbd48fbc2ee16347d19864e3116a8b327a5dc972358343915b2c185daa77b21\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/03/34/77e3ece0bba8b86bfac88a79f923b36d805cad63caeba38842\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: anyascii, pyahocorasick, textsearch, contractions\n",
            "Successfully installed anyascii-0.1.7 contractions-0.0.48 pyahocorasick-1.4.2 textsearch-0.0.21\n",
            "Requirement already satisfied: textsearch in /usr/local/lib/python3.7/dist-packages (0.0.21)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch) (0.1.7)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch) (1.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00XtRoYJzLCE"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiYUcmc2zQzj",
        "outputId": "375400cf-6fc7-4efa-e0a3-221adfea5466"
      },
      "source": [
        "dataset = pd.read_csv(r'https://github.com/dipanjanS/nlp_workshop_dhs18/raw/master/Unit%2011%20-%20Sentiment%20Analysis%20-%20Unsupervised%20Learning/movie_reviews.csv.bz2', compression='bz2')\n",
        "dataset.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     50000 non-null  object\n",
            " 1   sentiment  50000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 781.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PxD5STf-zTS9",
        "outputId": "156dbd74-06ab-42bc-f53d-961c83b086e7"
      },
      "source": [
        "# take a peek at the data\n",
        "dataset.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZXAHlptzXEJ"
      },
      "source": [
        "# build train and test datasets\n",
        "reviews = dataset['review'].values\n",
        "sentiments = dataset['sentiment'].values\n",
        "\n",
        "train_reviews = reviews[:35000]\n",
        "train_sentiments = sentiments[:35000]\n",
        "\n",
        "test_reviews = reviews[35000:]\n",
        "test_sentiments = sentiments[35000:]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdf34cuq0W6V"
      },
      "source": [
        "import contractions\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import re\n",
        "import tqdm\n",
        "import unicodedata\n",
        "\n",
        "\n",
        "def strip_html_tags(text):\n",
        "  soup = BeautifulSoup(text, \"html.parser\")\n",
        "  [s.extract() for s in soup(['iframe', 'script'])]\n",
        "  stripped_text = soup.get_text()\n",
        "  stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
        "  return stripped_text\n",
        "\n",
        "def remove_accented_chars(text):\n",
        "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "  return text\n",
        "\n",
        "def pre_process_corpus(docs):\n",
        "  norm_docs = []\n",
        "  for doc in tqdm.tqdm(docs):\n",
        "    doc = strip_html_tags(doc)\n",
        "    doc = doc.translate(doc.maketrans(\"\\n\\t\\r\", \"   \"))\n",
        "    doc = doc.lower()\n",
        "    doc = remove_accented_chars(doc)\n",
        "    doc = contractions.fix(doc)\n",
        "    # lower case and remove special characters\\whitespaces\n",
        "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
        "    doc = re.sub(' +', ' ', doc)\n",
        "    doc = doc.strip()  \n",
        "    norm_docs.append(doc)\n",
        "  \n",
        "  return norm_docs"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CRzsnGq0ZSK",
        "outputId": "e7358094-c719-46d7-efd5-647668c55b6b"
      },
      "source": [
        "%%time\n",
        "\n",
        "norm_train_reviews = pre_process_corpus(train_reviews)\n",
        "norm_test_reviews = pre_process_corpus(test_reviews)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35000/35000 [00:16<00:00, 2122.86it/s]\n",
            "100%|██████████| 15000/15000 [00:07<00:00, 2127.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 23.3 s, sys: 189 ms, total: 23.5 s\n",
            "Wall time: 23.6 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYjVqlz10c2_"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "To prepare text data for our deep learning model, we transform each review into a sequence.\n",
        "Every word in the review is mapped to an integer index and thus the sentence turns into a sequence of numbers.\n",
        "\n",
        "To perform this transformation, keras provides the ```Tokenizer```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf_Ck9Hc0oPo"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "t = tf.keras.preprocessing.text.Tokenizer(oov_token='<UNK>')\n",
        "# fit the tokenizer on the documents\n",
        "t.fit_on_texts(norm_train_reviews)\n",
        "t.word_index['<PAD>'] = 0"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jerA4iHk0qGF",
        "outputId": "59df257d-4318-4608-85b5-1cdadb3bc71c"
      },
      "source": [
        "max([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), min([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), t.word_index['<UNK>']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('dawgis', 175880), ('<PAD>', 0), 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtrRwXbI05Qr"
      },
      "source": [
        "train_sequences = t.texts_to_sequences(norm_train_reviews)\n",
        "test_sequences = t.texts_to_sequences(norm_test_reviews)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Invj0gRk0-RW",
        "outputId": "6f1a2621-2be5-4aa8-9403-fc38489cc543"
      },
      "source": [
        "print(\"Vocabulary size={}\".format(len(t.word_index)))\n",
        "print(\"Number of Documents={}\".format(t.document_count))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size=175881\n",
            "Number of Documents=35000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "Fq8BhTsM1AX2",
        "outputId": "cb28575c-5f09-457c-9aa5-2a905f28836a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "train_lens = [len(s) for s in train_sequences]\n",
        "test_lens = [len(s) for s in test_sequences]\n",
        "\n",
        "fig, ax = plt.subplots(1,2, figsize=(12, 6))\n",
        "h1 = ax[0].hist(train_lens)\n",
        "h2 = ax[1].hist(test_lens)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5ZMlD241CVr"
      },
      "source": [
        "### Sequence Normalization\n",
        "\n",
        "Not all reviews are of same length. To handle this difference in length of reviews, we define a maximum length.\n",
        "For reviews which are smaller than this length, we pad them with zeros which longer ones are truncated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CaP_1s41GCL"
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = 1000"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Op62mTZT1M4B",
        "outputId": "51c8dafe-6648-481e-9b56-822ec0c256ca"
      },
      "source": [
        "# pad dataset to a maximum review length in words\n",
        "X_train = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35000, 1000), (15000, 1000))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZZ1lLQw1Ols"
      },
      "source": [
        "### Encoding Labels\n",
        "\n",
        "The dataset contains labels of the form positive/negative. The following step encodes the labels using ```sklearn's``` ```LabelEncoder```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRBnWQGb1cRM"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "num_classes=2 # positive -> 1, negative -> 0"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOPPNySt1eDz"
      },
      "source": [
        "y_train = le.fit_transform(train_sentiments)\n",
        "y_test = le.transform(test_sentiments)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwlYATD11prp"
      },
      "source": [
        "VOCAB_SIZE = len(t.word_index)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1ScFo641sFW"
      },
      "source": [
        "# LSTM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaPlrBcU-3av"
      },
      "source": [
        "# Build Model Architecture\n",
        "\n",
        "\n",
        "# Embeddings\n",
        "\n",
        "The Embedding layer helps us generate the word embeddings from scratch. This layer\n",
        "is also initialized with some weights and is updated based on our optimizer, similar to\n",
        "weights on the neuron units in other layers when the network tries to minimize the loss\n",
        "in each epoch. Thus, the embedding layer tries to optimize its weights such that we get\n",
        "the best word embeddings that will generate minimum error in the model and capture\n",
        "semantic similarity and relationships among words. How do we get the embeddings?\n",
        "Let’s say we have a review with three terms ['movie', 'was', 'good'] and a vocab_map\n",
        "consisting of word to index mappings for 175860 words. \n",
        "\n",
        "![](https://i.imgur.com/WuV47DW.png)\n",
        "\n",
        "\n",
        "# LSTM\n",
        "\n",
        "LSTMs try to overcome\n",
        "the shortcomings of RNN models, especially with regard to handling long-term\n",
        "dependencies and problems that occur when the weight matrix associated with the\n",
        "units (neurons) become too small (leading to vanishing gradient) or too large (leading to\n",
        "exploding gradient). These architectures are more complex than regular deep networks\n",
        "and going into detailed internals and math concepts are out of the current scope, but we\n",
        "will try to cover the essentials here without making it math heavy\n",
        "\n",
        "![](https://i.imgur.com/c8qGKX8.png)\n",
        "\n",
        "The sequence of operations in the LSTM cell is briefly shown as follows.\n",
        "\n",
        "![](https://i.imgur.com/uiIbDk1.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M8LbmqR1vbO",
        "outputId": "9cf76988-ff14-42a0-9c82-c78ac395995d"
      },
      "source": [
        "EMBEDDING_DIM = 300 # dimension for dense embeddings for each token\n",
        "LSTM_DIM = 128 # total LSTM units\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
        "model.add(tf.keras.layers.SpatialDropout1D(0.1))\n",
        "model.add(tf.keras.layers.LSTM(LSTM_DIM, return_sequences=False))\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 1000, 300)         52764300  \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 1000, 300)         0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               219648    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 53,017,229\n",
            "Trainable params: 53,017,229\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRB4rNgo-533"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPqowrsh2vFb",
        "outputId": "3a4c691f-46db-49c0-d420-3de86424b2e4"
      },
      "source": [
        "batch_size = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
        "                                      patience=2,\n",
        "                                      restore_best_weights=True,\n",
        "                                      verbose=1)\n",
        "\n",
        "model.fit(X_train, y_train, epochs=EPOCHS, batch_size=batch_size, \n",
        "          callbacks=[es],\n",
        "          shuffle=True, validation_split=0.1, verbose=1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "247/247 [==============================] - 186s 621ms/step - loss: 0.5260 - accuracy: 0.7180 - val_loss: 0.3879 - val_accuracy: 0.8540\n",
            "Epoch 2/10\n",
            "247/247 [==============================] - 153s 618ms/step - loss: 0.1791 - accuracy: 0.9367 - val_loss: 0.4369 - val_accuracy: 0.8343\n",
            "Epoch 3/10\n",
            "247/247 [==============================] - 152s 617ms/step - loss: 0.0748 - accuracy: 0.9763 - val_loss: 0.6604 - val_accuracy: 0.8280\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00003: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4be3c35390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EzC-IW9-7sm"
      },
      "source": [
        "## Evaluate Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQvfAor127iS",
        "outputId": "5b69fdbe-23d1-48fb-a68b-7aff553f242e"
      },
      "source": [
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 12s 26ms/step - loss: 0.3659 - accuracy: 0.8635\n",
            "Accuracy: 86.35%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQZMB3akCjyl",
        "outputId": "25f8f329-88e9-42c9-8a91-a0f0ea74390e"
      },
      "source": [
        "predictions = (model.predict(X_test) > 0.5).astype(\"int32\").ravel()\n",
        "predictions[:10]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 1, 0, 1, 1, 1, 1], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCifYtx04Ia1",
        "outputId": "e164ea92-e99f-4905-dd35-eb7fe765dab4"
      },
      "source": [
        "predictions = ['positive' if item == 1 else 'negative' for item in predictions]\n",
        "predictions[:10]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['negative',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "GFUgpD9E4IgE",
        "outputId": "7974aace-2efb-4930-ae7f-de32b6996ed0"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "labels = ['negative', 'positive']\n",
        "print(classification_report(test_sentiments, predictions))\n",
        "pd.DataFrame(confusion_matrix(test_sentiments, predictions), index=labels, columns=labels)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.94      0.78      0.85      7490\n",
            "    positive       0.81      0.95      0.87      7510\n",
            "\n",
            "    accuracy                           0.86     15000\n",
            "   macro avg       0.87      0.86      0.86     15000\n",
            "weighted avg       0.87      0.86      0.86     15000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>negative</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>5821</td>\n",
              "      <td>1669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>379</td>\n",
              "      <td>7131</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          negative  positive\n",
              "negative      5821      1669\n",
              "positive       379      7131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq9Ccs3Y-_Fh"
      },
      "source": [
        "# Stacked LSTM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMSEnyBE_BSU"
      },
      "source": [
        "## Build Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8As3OAUg4Ijb",
        "outputId": "705d305d-9cde-4a4a-bd05-e634be62a1ad"
      },
      "source": [
        "model2 = tf.keras.models.Sequential()\n",
        "model2.add(tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH))\n",
        "model2.add(tf.keras.layers.SpatialDropout1D(0.1))\n",
        "model2.add(tf.keras.layers.LSTM(LSTM_DIM, return_sequences=True))\n",
        "model2.add(tf.keras.layers.LSTM(LSTM_DIM, return_sequences=False))\n",
        "model2.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model2.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model2.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 1000, 300)         52764300  \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 1000, 300)         0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 1000, 128)         219648    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 53,148,813\n",
            "Trainable params: 53,148,813\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYwqw31s_Ehx"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atBaIleW5RWI",
        "outputId": "5ca32bb3-254f-4895-deee-ee58f5b05ced"
      },
      "source": [
        "batch_size = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
        "                                      patience=2,\n",
        "                                      restore_best_weights=True,\n",
        "                                      verbose=1)\n",
        "\n",
        "model2.fit(X_train, y_train, epochs=EPOCHS, batch_size=batch_size, \n",
        "           callbacks=[es],\n",
        "           shuffle=True, validation_split=0.1, verbose=1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "247/247 [==============================] - 165s 658ms/step - loss: 0.4956 - accuracy: 0.7476 - val_loss: 0.3139 - val_accuracy: 0.8703\n",
            "Epoch 2/10\n",
            "247/247 [==============================] - 169s 684ms/step - loss: 0.1749 - accuracy: 0.9368 - val_loss: 0.3598 - val_accuracy: 0.8574\n",
            "Epoch 3/10\n",
            "247/247 [==============================] - 169s 684ms/step - loss: 0.0606 - accuracy: 0.9801 - val_loss: 0.3967 - val_accuracy: 0.8777\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00003: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4b934a2a50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLUkLa-d_IrV"
      },
      "source": [
        "## Evaluate Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGDVL22K5UZ_",
        "outputId": "68b74c6a-d5a1-462a-f936-a673f928e512"
      },
      "source": [
        "# Final evaluation of the model\n",
        "scores = model2.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 20s 42ms/step - loss: 0.3176 - accuracy: 0.8693\n",
            "Accuracy: 86.93%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHnuwJNW5VUT",
        "outputId": "f51cb1e1-583b-471a-bac5-dcb6b968bfc1"
      },
      "source": [
        "predictions = (model2.predict(X_test) > 0.5).astype(\"int32\").ravel()\n",
        "predictions[:10]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 1, 0, 1, 0, 1, 1], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksyEEPA25XeU",
        "outputId": "b1494a00-37a9-4c9d-e31c-1f6c15e4c55c"
      },
      "source": [
        "predictions = ['positive' if item == 1 else 'negative' for item in predictions]\n",
        "predictions[:10]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['negative',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'positive']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "jMS7pZ3a5XjD",
        "outputId": "c423d7ec-587b-4cb4-db63-ac7649ce235b"
      },
      "source": [
        "labels = ['negative', 'positive']\n",
        "print(classification_report(test_sentiments, predictions))\n",
        "pd.DataFrame(confusion_matrix(test_sentiments, predictions), index=labels, columns=labels)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      0.90      0.87      7490\n",
            "    positive       0.89      0.84      0.87      7510\n",
            "\n",
            "    accuracy                           0.87     15000\n",
            "   macro avg       0.87      0.87      0.87     15000\n",
            "weighted avg       0.87      0.87      0.87     15000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>negative</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>6728</td>\n",
              "      <td>762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>1198</td>\n",
              "      <td>6312</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          negative  positive\n",
              "negative      6728       762\n",
              "positive      1198      6312"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}